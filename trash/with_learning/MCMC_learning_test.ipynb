{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan 2\n",
    "\n",
    "@author: yaning\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.distributions import Normal, Uniform\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# functions and classes that i wrote\n",
    "import with_learning.run_network as run_network\n",
    "import with_learning.learning_NN.Receptors as Receptors\n",
    "import with_learning.learning_NN.Network as Network\n",
    "\n",
    "importlib.reload(Receptors)\n",
    "importlib.reload(Network)\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "path = \"/home/yaning/Documents/Spiking_NN/with_learning/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointCount = 6500\n",
    "deltaTms = 0.05\n",
    "times = np.arange(pointCount) * deltaTms\n",
    "initial_Vm = 1.3458754117369027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "# get the minimum and maximum of the voltages\n",
    "def get_min_max_distance(voltages):\n",
    "    min_voltage = abs(np.nanmin(voltages) + 70)\n",
    "    max_voltage = abs(np.nanmax(voltages) - 40.1)\n",
    "    return min_voltage, max_voltage\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def get_current_distance(currents):\n",
    "    current_d = abs(np.nanmax(currents)-175)\n",
    "    return current_d\n",
    "\n",
    "def get_nan_inf_amount(arr):\n",
    "    return np.isinf(arr).sum() + np.isnan(arr).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_synapses = []\n",
    "\n",
    "def create_synapse(send_neuron, receive_neuron, type):\n",
    "    \n",
    "    # create receptors accordingly\n",
    "    if type == \"AMPA\":\n",
    "        # temporal solution for weight randomise\n",
    "        # Receptors.LigandGatedChannelFactory.set_params()\n",
    "        ampa_receptor = Receptors.AMPA(0.0072, 1, -70, 1.35, 0.9, 1, 1, 1, 12, 10, 20, 10, 35, 7, 0.7, \"AMPA\")\n",
    "        synapse = Network.Synapse(0.05, 0, send_neuron, receive_neuron, ampa_receptor)\n",
    "        \n",
    "    elif type == \"AMPA+NMDA\":\n",
    "        # Receptors.LigandGatedChannelFactory.set_params()\n",
    "        ampa_receptor = Receptors.AMPA(0.0072, 1, -70, 1.35, 0.9, 1, 1, 1, 12, 10, 20, 10, 35, 7, 0.7, \"AMPA\")\n",
    "        nmda_receptor = Receptors.NMDA(0.0012, 1, -70, 1.35, 0.9, 1, 1, 1, 12, 10, 20, 10, 15, 7, 0.7, \"NMDA\")\n",
    "        synapse = Network.Synapse(0.05, 0, send_neuron, receive_neuron, ampa_receptor, nmda_receptor)\n",
    "    \n",
    "    elif type == \"GABA\":\n",
    "        # Receptors.LigandGatedChannelFactory.set_params()\n",
    "        # print(Receptors.LigandGatedChannelFactory.w_init_GABA)\n",
    "        gaba_receptor = Receptors.GABA(0.0012, 1, -140, 1.35, 0.9, 1, 1, 1, 12, 10, 20, 10, 20, 7, 0.7, \"GABA\")\n",
    "        synapse = Network.Synapse(0.05, 0, send_neuron, receive_neuron, gaba_receptor)\n",
    "\n",
    "    send_neuron.outgoing_synapses.append(synapse)\n",
    "    receive_neuron.incoming_synapses.append(synapse)\n",
    "\n",
    "    all_synapses.append(synapse)\n",
    "\n",
    "def update_synapse_initial_values(infer_params):\n",
    "    for synapse in all_synapses:\n",
    "        for receptor in synapse.receptors:\n",
    "            receptor.Vm = initial_Vm\n",
    "            receptor.gP = 1\n",
    "            \n",
    "            receptor.e = infer_params[\"e\"]\n",
    "            receptor.u_se = infer_params[\"u_se\"]\n",
    "            receptor.g_decay = infer_params[\"g_decay\"]\n",
    "            receptor.g_rise = infer_params[\"g_rise\"]\n",
    "            receptor.w = infer_params[\"w\"]\n",
    "            receptor.tau_rec = infer_params[\"tau_rec\"]\n",
    "            receptor.tau_pre = infer_params[\"tau_pre\"]\n",
    "            receptor.tau_post = infer_params[\"tau_post\"]\n",
    "\n",
    "            if receptor.label == \"GABA\":\n",
    "                receptor.gMax = infer_params[\"gMax_GABA\"]\n",
    "                receptor.tau_decay = infer_params[\"tau_decay_GABA\"]\n",
    "                receptor.tau_rise = infer_params[\"tau_rise_GABA\"]\n",
    "            \n",
    "            elif receptor.label == \"NMDA\":\n",
    "                receptor.tau_decay = infer_params[\"tau_decay_NMDA\"]\n",
    "                receptor.tau_rise = infer_params[\"tau_rise_NMDA\"]\n",
    "            \n",
    "            elif receptor.label == \"AMPA\":\n",
    "                receptor.tau_decay = infer_params[\"tau_decay_AMPA\"]\n",
    "                receptor.tau_rise = infer_params[\"tau_rise_AMPA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pattern = np.load(path + \"dataset.npy\") \n",
    "output_pattern = np.load(path + \"output.npy\")\n",
    "\n",
    "input_pattern = input_pattern[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6500)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pattern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"XOR_dataset_black_white.pkl\", \"rb\") as f:\n",
    "    dataset, binary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 6000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------1 input, 1 excite main, 1 excite sub, 1 inhibit main, 1 inhibit sub, output-----------\n",
    "\n",
    "# create the network\n",
    "# Neuron: deltaTms, I, Vm, Name\n",
    "neuron_input_0 = Network.Neuron(deltaTms, 0, initial_Vm, \"input_0\")\n",
    "neuron_input_1 = Network.Neuron(deltaTms, 0, initial_Vm, \"input_1\")\n",
    "neuron_input_2 = Network.Neuron(deltaTms, 0, initial_Vm, \"input_2\")\n",
    "\n",
    "neuron_excite_main = Network.Neuron(deltaTms, 0, initial_Vm, \"excite_main\")\n",
    "neuron_excite_sub = Network.Neuron(deltaTms, 0, initial_Vm, \"excite_sub\")\n",
    "\n",
    "neuron_inhibit_main = Network.Neuron(deltaTms, 0, initial_Vm, \"inhibit_main\")\n",
    "neuron_inhibit_sub = Network.Neuron(deltaTms, 0, initial_Vm, \"inhibit_sub\")\n",
    "\n",
    "neuron_output = Network.Neuron(deltaTms, 0, initial_Vm, \"output\")\n",
    "\n",
    "neurons = [neuron_input_0, neuron_input_1, neuron_input_2, \n",
    "           neuron_excite_main, neuron_excite_sub, \n",
    "        neuron_inhibit_main, neuron_inhibit_sub, neuron_output]\n",
    "\n",
    "neuron_names = [\"input_0\", \"input_1\", \"input_2\",\n",
    "                \"excite_main\", \"excite_sub\", \"inhibit_main\", \"inhibit_sub\", \"output\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*********************full layer***************************\n",
    "# ----------------first input layer------------------------\n",
    "create_synapse(neuron_input_0, neuron_excite_main, \"AMPA\")\n",
    "create_synapse(neuron_input_1, neuron_excite_main, \"AMPA\")\n",
    "create_synapse(neuron_input_2, neuron_excite_main, \"AMPA\")\n",
    "\n",
    "create_synapse(neuron_input_0, neuron_inhibit_main, \"GABA\")\n",
    "create_synapse(neuron_input_1, neuron_inhibit_main, \"GABA\")\n",
    "create_synapse(neuron_input_2, neuron_inhibit_main, \"GABA\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------self recurrent layer----------------\n",
    "create_synapse(neuron_excite_main, neuron_excite_sub, \"AMPA+NMDA\")\n",
    "create_synapse(neuron_excite_sub, neuron_excite_main, \"AMPA+NMDA\")\n",
    "\n",
    "create_synapse(neuron_inhibit_main, neuron_inhibit_sub, \"GABA\")\n",
    "create_synapse(neuron_inhibit_sub, neuron_inhibit_main, \"GABA\")\n",
    "\n",
    "# --------------between excitatory and inhibitory----------------\n",
    "create_synapse(neuron_excite_main, neuron_inhibit_main, \"AMPA+NMDA\")\n",
    "create_synapse(neuron_inhibit_main, neuron_excite_main, \"GABA\")\n",
    "\n",
    "\n",
    "# ----------------output layer----------------------\n",
    "create_synapse(neuron_excite_main, neuron_output, \"AMPA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6500)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pattern.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_pattern):\n",
    "    currents = []\n",
    "\n",
    "    for t in range(pointCount):\n",
    "        currents_tstep = []\n",
    "        \n",
    "        if input_pattern[0,t]:\n",
    "            neuron_input_0.sending_signal()\n",
    "            neuron_input_0.fire_tstep.append(t)\n",
    "            \n",
    "        if input_pattern[1,t]:\n",
    "            neuron_input_1.sending_signal()\n",
    "            neuron_input_1.fire_tstep.append(t)\n",
    "            \n",
    "        if input_pattern[2,t]:\n",
    "            neuron_input_2.sending_signal()\n",
    "            neuron_input_2.fire_tstep.append(t)\n",
    "\n",
    "\n",
    "        # update the synapse states then each neuron\\\n",
    "        num_cycle = 0\n",
    "        for neuron in neurons[3:]:\n",
    "            if neuron.fire_tstep == []:\n",
    "                last_fire = -2\n",
    "            else:\n",
    "                last_fire = neuron.fire_tstep[-1]\n",
    "            fire = neuron.check_firing(t)\n",
    "            if fire:\n",
    "                if neuron.fire_tstep == [] or last_fire + 1 != t:\n",
    "                    # print(\"this line runs\")\n",
    "                    neuron.update_weights(t)\n",
    "\n",
    "            \n",
    "            neuron.update()\n",
    "            \n",
    "            # only record output current\n",
    "            if num_cycle == 4:\n",
    "                currents_tstep.append(neuron.I)\n",
    "            num_cycle += 1\n",
    "            \n",
    "        # set the synapse states back to 0\n",
    "        for synapse in all_synapses:\n",
    "            synapse.state = 0\n",
    "        \n",
    "        currents.append(currents_tstep)\n",
    "    return currents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_params = {\n",
    "    # this might be extremly small\n",
    "    \"gMax_GABA\" : 0.01,\n",
    "    \n",
    "    # between 0-1\n",
    "    \"e\" : 1, # has to be 0-1 because the differentiate formula\n",
    "    \"u_se\" : 1, # fraction of avaible transmitter \n",
    "    \n",
    "    # do not need to be between 0-1\n",
    "    \"g_decay\" : 1, # technically substraction of \n",
    "    \"g_rise\" : 1, # both should be smaller than 1 (fraction)\n",
    "\n",
    "    \"w\" : 1,\n",
    "\n",
    "    \"tau_rec\" : 10,\n",
    "    \"tau_pre\" : 20,\n",
    "    \"tau_post\" : 20,\n",
    "    \n",
    "    \"tau_decay_AMPA\" : 35,\n",
    "    \"tau_rise_AMPA\" : 7,\n",
    "    \"tau_decay_NMDA\" : 20,\n",
    "    \"tau_rise_NMDA\" : 9,\n",
    "    \"tau_decay_GABA\" : 40,\n",
    "    \"tau_rise_GABA\" : 5 \n",
    "    }\n",
    "\n",
    "infer_names = [\"gMax_GABA\", \"e\", \"u_se\", \"g_decay\", \"g_rise\", \"w\", \"tau_rec\",\n",
    "               \"tau_pre\", \"tau_post\", \"tau_decay_AMPA\", \"tau_rise_AMPA\",\n",
    "               \"tau_decay_NMDA\", \"tau_rise_NMDA\", \"tau_decay_GABA\", \"tau_rise_GABA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# run(input_pattern)\n",
    "# for neuron in neurons:\n",
    "#     neuron.erase(initial_Vm)\n",
    "# update_synapse_initial_values(infer_params)\n",
    "# print(\"Time taken:\", time.time() - start)\n",
    "\n",
    "# times = []\n",
    "# for i in range(500):\n",
    "#     start = time.time()\n",
    "#     run(input_pattern)\n",
    "#     for neuron in neurons:\n",
    "#         neuron.erase(initial_Vm)\n",
    "#     update_synapse_initial_values(infer_params)\n",
    "#     times.append(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start = time.time()\n",
    "# Normal(last_pure_sample[j], std).sample().numpy()\n",
    "# # print(\"Time taken:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                                          | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_437359/712293747.py:105: RuntimeWarning: overflow encountered in exp\n",
      "  score_old_softmax = np.exp(lambda_value * score_old) / (np.exp(lambda_value*score_old) + np.exp(lambda_value*score_new))\n",
      "/tmp/ipykernel_437359/712293747.py:106: RuntimeWarning: overflow encountered in exp\n",
      "  score_new_softmax = np.exp(lambda_value * score_new) / (np.exp(lambda_value*score_old) + np.exp(lambda_value*score_new))\n",
      "/tmp/ipykernel_437359/712293747.py:106: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  score_new_softmax = np.exp(lambda_value * score_new) / (np.exp(lambda_value*score_old) + np.exp(lambda_value*score_new))\n",
      "Processing:   0%|                                                  | 1/1000 [00:00<16:33,  1.01it/s]/home/yaning/Documents/Spiking_NN/with_learning/learning_NN/Receptors.py:180: RuntimeWarning: overflow encountered in scalar divide\n",
      "  return -g_decay/self.tau_decay + w*e\n",
      "/home/yaning/Documents/Spiking_NN/with_learning/learning_NN/Receptors.py:153: RuntimeWarning: invalid value encountered in scalar add\n",
      "  k2 = f(y0 + h*k1/2, *arg)\n",
      "Processing:   3%|█▌                                               | 33/1000 [00:33<16:00,  1.01it/s]/home/yaning/Documents/Spiking_NN/with_learning/learning_NN/Receptors.py:180: RuntimeWarning: invalid value encountered in scalar add\n",
      "  return -g_decay/self.tau_decay + w*e\n",
      "/home/yaning/Documents/Spiking_NN/with_learning/learning_NN/Receptors.py:184: RuntimeWarning: invalid value encountered in scalar add\n",
      "  return -g_rise/self.tau_rise + w*e\n",
      "Processing:   4%|██▏                                              | 45/1000 [00:46<16:03,  1.01s/it]/home/yaning/Documents/Spiking_NN/with_learning/learning_NN/Receptors.py:56: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  I = self.gMax * self.gP *(self.Vm - self.rE)\n",
      "Processing: 100%|███████████████████████████████████████████████| 1000/1000 [18:24<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# # try use MCMC result params\n",
    "# path = \"/home/yaning/Documents/Spiking_NN/without_learning/\"\n",
    "# samples = np.load(path + \"MCMC_samples/static_std_initial_0.npy\")\n",
    "# cut_samples = samples[1000:, :]\n",
    "# values = np.mean(cut_samples, axis=0)\n",
    "# infer_names = Receptors.LigandGatedChannelFactory.infer_names\n",
    "# infer_params = dict(zip(infer_names, values))\n",
    "\n",
    "start = time.time()\n",
    "#-------------------------initialise MCMC---------------------------\n",
    "samples = []\n",
    "pure_samples = []\n",
    "\n",
    "for i, key in enumerate(infer_params):\n",
    "    if i <= 2:\n",
    "        infer_params[key] = 0.5\n",
    "    else:\n",
    "        # factor is 30, multiply by 0.5 (initial)\n",
    "        infer_params[key] = 15\n",
    "\n",
    "initial_sample = []\n",
    "for key in infer_params:\n",
    "    initial_sample.append(infer_params[key])\n",
    "\n",
    "# put first pure and normal samples in the record\n",
    "pure_samples.append(np.zeros(len(infer_params)))\n",
    "samples.append(initial_sample)\n",
    "\n",
    "# run first round\n",
    "# return voltages, currents, neuron_names\n",
    "update_synapse_initial_values(infer_params)\n",
    "currents = run(input_pattern)\n",
    "\n",
    "# # evaluation scores\n",
    "# old_score = abs(235-len(firing_tstep))\n",
    "# min_voltage_old, max_voltage_old = get_min_max_distance(voltages)\n",
    "\n",
    "# score_old = get_nan_inf_amount(voltages) + get_nan_inf_amount(currents)\n",
    "score_old = get_current_distance(currents)\n",
    "\n",
    "\n",
    "# print(\"Time taken to finish initial run:\", time.time() - start)\n",
    "#-----------------------officially run MCMC----------------------\n",
    "num = 1000\n",
    "big_factor = 30\n",
    "small_factor = 0.01\n",
    "\n",
    "for i in tqdm(range(num), desc=\"Processing\", ncols=100):\n",
    "    # # make the std decrease as MCMC keeps sampling\n",
    "    # std = np.exp(-i*3/num)\n",
    "    std = 8/(1+(24/num)*i)\n",
    "    # std = 6\n",
    "    start = time.time()\n",
    "    one_round_pure_sample = []\n",
    "    one_round_sample = []\n",
    "    \n",
    "    temp_infer_params = {}\n",
    "    \n",
    "    last_pure_sample = pure_samples[-1]\n",
    "\n",
    "    for j in range(len(infer_params)):\n",
    "        # using j only for separate with and without factor\n",
    "        temp_pure_sample = Normal(last_pure_sample[j], std).sample().item()\n",
    "        # temp_pure_sample = 1\n",
    "        one_round_pure_sample.append(temp_pure_sample)\n",
    "        # if j == 0:\n",
    "        #     temp_infer_params[infer_names[j]] = small_factor*sigmoid(temp_pure_sample)\n",
    "        if j <= 2:\n",
    "            temp_infer_params[infer_names[j]] = sigmoid(temp_pure_sample)\n",
    "        else:\n",
    "            temp_infer_params[infer_names[j]] = big_factor*sigmoid(temp_pure_sample)\n",
    "\n",
    "    # print(temp_infer_params)\n",
    "    # print(\"Time taken to choose params:\", time.time() - start)\n",
    "    # print(one_round_pure_sample)\n",
    "    # run with sampled value\n",
    "    \n",
    "    # print(temp_infer_params)\n",
    "    # restart the network\n",
    "    for neuron in neurons:\n",
    "        neuron.erase(initial_Vm)\n",
    "    update_synapse_initial_values(temp_infer_params)\n",
    "    # print(all_synapses[0].receptors[0].w)\n",
    "    \n",
    "    start = time.time()\n",
    "    currents = run(input_pattern)\n",
    "    # print(\"Time taken to finish mcmc run:\", time.time() - start)\n",
    "    # # evaluation scores\n",
    "    # new_score = abs(235-len(firing_tstep))\n",
    "    # acceptance_ratio = old_score/new_score\n",
    "    # print(old_score, new_score)\n",
    "    \n",
    "    # min_voltage_new, max_voltage_new = get_min_max_distance(voltages)\n",
    "    # min_voltage_rate = min_voltage_old/min_voltage_new\n",
    "    # max_voltage_rate = max_voltage_old/max_voltage_new\n",
    "    \n",
    "    # acceptance_ratio = max_voltage_rate\n",
    "    # print(min_voltage_new, max_voltage_new)\n",
    "    # print(acceptance_ratio)\n",
    "    # score_new = get_nan_inf_amount(voltages) + get_nan_inf_amount(currents)\n",
    "    start = time.time()\n",
    "    score_new = get_current_distance(currents)\n",
    "    lambda_value = 0.01\n",
    "    # print(score_new, score_old)\n",
    "    score_old_softmax = np.exp(lambda_value * score_old) / (np.exp(lambda_value*score_old) + np.exp(lambda_value*score_new))\n",
    "    score_new_softmax = np.exp(lambda_value * score_new) / (np.exp(lambda_value*score_old) + np.exp(lambda_value*score_new))\n",
    "    \n",
    "    acceptance_ratio = score_old_softmax/score_new_softmax\n",
    "    # print(score_old, score_new)\n",
    "    # print(acceptance_ratio)\n",
    "\n",
    "    u = np.random.uniform(0, 1)\n",
    "\n",
    "    if acceptance_ratio >= u:\n",
    "        # print(\"replace\")\n",
    "        # old_score = new_score\n",
    "        # current_d_old = current_d_new\n",
    "        # min_voltage_old = min_voltage_new\n",
    "        # max_voltage_old = max_voltage_new\n",
    "        score_old = score_new\n",
    "\n",
    "        \n",
    "        infer_params = temp_infer_params\n",
    "        # if accept new, the add the pure for next round use\n",
    "        pure_samples.append(one_round_pure_sample)\n",
    "\n",
    "    \n",
    "    for key in infer_params:\n",
    "        one_round_sample.append(infer_params[key])\n",
    "    \n",
    "    samples.append(one_round_sample)\n",
    "    # print(\"Time taken to finish choose the sample:\", time.time() - start)\n",
    "    \n",
    "\n",
    "samples = np.array(samples)\n",
    "pure_samples = np.array(pure_samples)\n",
    "\n",
    "\n",
    "np.save(path + 'MCMC_samples/samples_local.npy', samples)\n",
    "np.save(path + 'MCMC_samples/pure_samples_local.npy', pure_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(path + \"infer_params_names.pkl\", \"wb\") as f:\n",
    "    pickle.dump((infer_params, infer_names), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
