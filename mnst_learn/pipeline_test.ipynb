{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6bf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 13\n",
    "\n",
    "@author: yaning\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35ba96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.u_se_ampa = 0.5\n",
    "        self.u_se_nmda = 0.5\n",
    "        self.u_se_gaba = 0.5\n",
    "        self.tau_rec_ampa = 14.1\n",
    "        self.tau_rec_nmda = 12.0\n",
    "        self.tau_rec_gaba = 7.2\n",
    "        self.tau_rise_ampa = 8.72\n",
    "        self.tau_rise_nmda = 136.0\n",
    "        self.tau_rise_gaba = 19.9\n",
    "        self.learning_rate = 1.0\n",
    "        self.weight_scale = 1.0\n",
    "\n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd19f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fire_lower(mp):\n",
    "    activeness = (mp > 5).float()\n",
    "    return activeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fcbcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/yaning/Documents/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# with open(path + \"fire_data_10p_8f_non_zero_background.pkl\", \"rb\") as f:\n",
    "with open(path + \"fire_data_mnst_all.pkl\", \"rb\") as f:\n",
    "# with open(path + \"fire_data_gabor_binary_rotate_mix_diff.pkl\", \"rb\") as f:\n",
    "# with open(path + \"fire_data_gabor_binary_two.pkl\", \"rb\") as f:\n",
    "    fire_data = pickle.load(f)\n",
    "\n",
    "train = False\n",
    "\n",
    "fire_data = torch.tensor(fire_data, device=device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e25f66bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 10, 10, 8, 4000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7f0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data = fire_data[21].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f03505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "0\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "1\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "2\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "3\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "4\n",
      "same\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "5\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "6\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "7\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "8\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "9\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "10\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "11\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "12\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "13\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "14\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "15\n",
      "same\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "16\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "17\n",
      "same\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "18\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "19\n",
      "same\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "20\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "21\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "22\n",
      "same\n",
      "Progress: 0/4000 (0.0%)\n",
      "Progress: 1000/4000 (25.0%)\n",
      "Progress: 2000/4000 (50.0%)\n",
      "Progress: 3000/4000 (75.0%)\n",
      "23\n",
      "Progress: 0/4000 (0.0%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 537\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# Out_fires[t] = Out_fire\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# Out_fires[t] = Out_mp\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# update them by each layer connection, cannot do it at the same time because\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# the shapes are different\u001b[39;00m\n\u001b[1;32m    536\u001b[0m E_states \u001b[38;5;241m=\u001b[39m update_states(E_mp, E_states) \n\u001b[0;32m--> 537\u001b[0m E_es, E_g_decays, E_g_rises, E_gPs \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_gPs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE_es\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE_ws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE_g_decays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE_g_rises\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mIn_fire\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE_fire\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI_fire\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m I_states \u001b[38;5;241m=\u001b[39m update_states(I_mp, I_states)\n\u001b[1;32m    541\u001b[0m I_es, I_g_decays, I_g_rises, I_gPs \u001b[38;5;241m=\u001b[39m update_gPs(I_es, I_ws, I_g_decays, I_g_rises, [E_fire, I_fire], \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 171\u001b[0m, in \u001b[0;36mupdate_gPs\u001b[0;34m(es, ws, g_decays, g_rises, fires, recurrent, deltaTms)\u001b[0m\n\u001b[1;32m    167\u001b[0m     e[e \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# deltaTms * 10 is not good, when try to find the right params need to delete this\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m g_decay \u001b[38;5;241m=\u001b[39m \u001b[43mrunge_kutta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_decay_deri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_decays\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltaTms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mws\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfire\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m g_rise \u001b[38;5;241m=\u001b[39m runge_kutta(g_rise_deri, g_rises[i], deltaTms, ws[i], e, fire)\n\u001b[1;32m    175\u001b[0m gP \u001b[38;5;241m=\u001b[39m g_rise \u001b[38;5;241m-\u001b[39m g_decay\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pic_index in range(fire_data.shape[0]):\n",
    "    one_pic = fire_data[pic_index]\n",
    "\n",
    "\n",
    "    # parameters\n",
    "    gMax_Na = 120\n",
    "    rE_Na = 115\n",
    "\n",
    "    gMax_K = 36\n",
    "    rE_K = -12\n",
    "\n",
    "    gMax_leaky = 0.3\n",
    "    rE_leaky = 10.6\n",
    "\n",
    "    deltaTms = 0.05\n",
    "    Cm = 1\n",
    "    pointCount = fire_data.shape[-1]\n",
    "\n",
    "    # siemens unit n_s\n",
    "    # gMax_AMPA = 0.00072\n",
    "    # gMax_NMDA = 0.0012\n",
    "    # gMax_GABA = 0.0004\n",
    "\n",
    "    gMax_AMPA = 0.00072 \n",
    "    gMax_NMDA = 0.0012\n",
    "    gMax_GABA = 0.004\n",
    "    # gMax_GABA = 0.006\n",
    "\n",
    "    # # below are from the book\n",
    "    # gMax_AMPA = 0.72\n",
    "    # gMax_NMDA = 1.2\n",
    "    # gMax_GABA = 0.04\n",
    "\n",
    "    rE_AMPA = 70\n",
    "    rE_NMDA = 70\n",
    "    rE_GABA = 0\n",
    "\n",
    "    mg = 0.01\n",
    "    # mg = 1.2\n",
    "\n",
    "    threshold = -50 + 70\n",
    "    current_threshold = -200\n",
    "\n",
    "\n",
    "    # # guesses\n",
    "    # u_se = torch.tensor([0.9, 0.9, 0.9], device=device)\n",
    "    # tau_rec = torch.tensor([5, 12, 12], device=device)\n",
    "    # guesses\n",
    "    u_se = torch.tensor([params.u_se_ampa, params.u_se_nmda, params.u_se_gaba], device=device)\n",
    "    tau_rec = torch.tensor([params.tau_rec_ampa, params.tau_rec_nmda, params.tau_rec_gaba], device=device)\n",
    "    tau_rec = tau_rec\n",
    "\n",
    "    # below from paper \n",
    "    tau_pre = torch.tensor([20, 20, 20], device=device)\n",
    "    tau_pre = tau_pre\n",
    "    tau_decay = torch.tensor([2.4, 100, 7], device=device)\n",
    "    tau_decay = tau_decay\n",
    "\n",
    "    # rise has to be quicker than decay, tau needs to be bigger (negative deri)\n",
    "    # tau_rise = torch.tensor([1, 50, 3], device=device)\n",
    "    tau_rise = torch.tensor([params.tau_rise_ampa, params.tau_rise_nmda, params.tau_rise_gaba], device=device)\n",
    "    tau_rise = tau_rise\n",
    "    # guesses\n",
    "    # learning_rate = 100\n",
    "    # weight_scale = 10\n",
    "\n",
    "    learning_rate = params.learning_rate\n",
    "    weight_scale = params.weight_scale\n",
    "\n",
    "\n",
    "    # generate the exponential decrease with time gap values\n",
    "    gaps = torch.arange(400, 0, -1, device=device).unsqueeze(0).expand(3,400)\n",
    "    temp_tau_pre = tau_pre.unsqueeze(-1)\n",
    "    weight_values_matrix = torch.exp(-gaps/temp_tau_pre)\n",
    "\n",
    "    for _ in range(5):\n",
    "        weight_values_matrix = weight_values_matrix.unsqueeze(1)\n",
    "\n",
    "\n",
    "    def update_states(mp, current_states, deltaTms=0.05):\n",
    "            m_alpha = .1*((25-mp) / (torch.exp((25-mp)/10)-1))\n",
    "            m_beta = 4*torch.exp(-mp/18)\n",
    "            n_alpha = .01 * ((10-mp) / (torch.exp((10-mp)/10)-1))\n",
    "            n_beta = .125*torch.exp(-mp/80)\n",
    "            h_alpha = .07*torch.exp(-mp/20)\n",
    "            h_beta = 1/(torch.exp((30-mp)/10)+1)\n",
    "\n",
    "            alphas = torch.stack([m_alpha, n_alpha, h_alpha], dim=0)\n",
    "            betas = torch.stack([m_beta, n_beta, h_beta], dim=0)\n",
    "\n",
    "            alpha_states = alphas*(1-current_states)\n",
    "            beta_states = betas*current_states\n",
    "\n",
    "            new_states = current_states + deltaTms*(alpha_states - beta_states)\n",
    "\n",
    "            return new_states\n",
    "\n",
    "    def broadcast_params(param, target):\n",
    "        # param = param[:,None]*torch.ones_like(target)[None,...]\n",
    "        new_shape = (3,) + (1,)*(target.dim()-1)\n",
    "        param = param.view(new_shape)\n",
    "        param = param.expand_as(target)\n",
    "        return param\n",
    "\n",
    "    def broadcast_mp(mp, connection_matrix):\n",
    "        num_missing_dim = connection_matrix.dim() - mp.dim()\n",
    "        mp = mp.view(*([1]*num_missing_dim), *mp.shape)\n",
    "        mp = mp.expand_as(connection_matrix)\n",
    "        return mp\n",
    "\n",
    "\n",
    "    def runge_kutta(f, y0, h, *arg):\n",
    "        k1 = f(y0, *arg)\n",
    "        k2 = f(y0 + h*k1/2, *arg)\n",
    "        k3 = f(y0 + h*k2/2, *arg)\n",
    "        k4 = f(y0 + h*k3, *arg)\n",
    "\n",
    "        next = y0 + h/6*(k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "        return next\n",
    "\n",
    "    # # deri as deriviation \n",
    "    # def e_deri(e, on_off):\n",
    "    #     return (1-e)/tau_rec[None,:,None,None] - u_se[None,:,None,None]*on_off\n",
    "\n",
    "    # def g_decay_deri(g_decay, w, e, on_off):\n",
    "    #     return -g_decay/tau_decay[None,:,None,None] + w*e*on_off\n",
    "\n",
    "    # def g_rise_deri(g_rise, w, e, on_off):\n",
    "    #     return -g_rise/tau_rise[None,:,None,None] + w*e*on_off\n",
    "\n",
    "    # deri as deriviation \n",
    "    def e_deri(e, on_off):\n",
    "        tau_rec_broad = broadcast_params(tau_rec, e)\n",
    "        u_se_broad = broadcast_params(u_se, e)\n",
    "        return (1-e)/tau_rec_broad - u_se_broad*on_off*e\n",
    "\n",
    "    def g_decay_deri(g_decay, w, e, on_off):\n",
    "        tau_decay_broad = broadcast_params(tau_decay, e)\n",
    "        return -g_decay/tau_decay_broad + w*e*on_off\n",
    "\n",
    "    def g_rise_deri(g_rise, w, e, on_off):\n",
    "        tau_rise_broad = broadcast_params(tau_rise, e)\n",
    "        return -g_rise/tau_rise_broad + w*e*on_off\n",
    "\n",
    "    def update_gPs(es, ws, g_decays, g_rises, fires, recurrent, deltaTms=0.05):\n",
    "        # cycle is how many layers it connects \n",
    "        cycle = len(es)\n",
    "        new_es = []\n",
    "        new_g_decays = []\n",
    "        new_g_rises = []\n",
    "        gPs = []\n",
    "        \n",
    "        for i in range(cycle):\n",
    "\n",
    "            fire = fires[i]\n",
    "            fire = fire.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "            fire = fire.expand(*es[i].shape)\n",
    "\n",
    "            if recurrent and i == 0:\n",
    "                e = es[i]\n",
    "                e.fill_(1)\n",
    "            else:\n",
    "                e = runge_kutta(e_deri, es[i], deltaTms, fire)\n",
    "            if (e < 0).any():\n",
    "                print(\"e negative\")\n",
    "                e[e < 0] = 0\n",
    "\n",
    "\n",
    "            # deltaTms * 10 is not good, when try to find the right params need to delete this\n",
    "            g_decay = runge_kutta(g_decay_deri, g_decays[i], deltaTms, ws[i], e, fire)\n",
    "            g_rise = runge_kutta(g_rise_deri, g_rises[i], deltaTms, ws[i], e, fire)\n",
    "\n",
    "\n",
    "            gP = g_rise - g_decay\n",
    "            if (gP < 0).any():\n",
    "                print(\"gP negative\")\n",
    "                gP[gP < 0] = 0\n",
    "                \n",
    "            new_es.append(e)\n",
    "            new_g_decays.append(g_decay)\n",
    "            new_g_rises.append(g_rise)\n",
    "            gPs.append(gP)\n",
    "\n",
    "        return new_es, new_g_decays, new_g_rises, gPs\n",
    "\n",
    "\n",
    "    def initialise(*args):\n",
    "        d = args[0]\n",
    "\n",
    "        # cells, states, mp are fine with only individual cells\n",
    "        cells = torch.zeros((d, d), device=device)\n",
    "\n",
    "        m_states = cells.clone()\n",
    "        m_states.fill_(0.061956531255774015)\n",
    "\n",
    "        n_states = cells.clone()\n",
    "        n_states.fill_(0.3384883478113268)\n",
    "\n",
    "        h_states = cells.clone()\n",
    "        h_states.fill_(0.5484107720738856)\n",
    "\n",
    "        states = torch.stack([m_states, n_states, h_states], dim=0)\n",
    "\n",
    "        mp = cells.clone()\n",
    "        mp.fill_(1.3458754117369027)\n",
    "\n",
    "        # the synapses properties are not individual cell but \n",
    "        # shape as the connections\n",
    "\n",
    "        es = []\n",
    "        ws = []\n",
    "        g_decays = []\n",
    "        g_rises = []\n",
    "\n",
    "        # if randomize:\n",
    "        for arg in args[1:]:\n",
    "            gaussian = arg[1]\n",
    "            weight = arg[2]\n",
    "            arg = arg[0]\n",
    "\n",
    "            muster = torch.zeros(arg.shape, device=device)\n",
    "\n",
    "            e = muster.clone()\n",
    "            e.fill_(1)\n",
    "            es.append(e)\n",
    "\n",
    "            #---------------------about weight---------------------------------------\n",
    "            if not gaussian:\n",
    "                w = torch.rand(*arg.shape[1:], device=device)*weight\n",
    "            else:\n",
    "                w = torch.ones(*arg.shape[1:], device=device)*weight\n",
    "\n",
    "            shape = [3] + [1]*w.ndim\n",
    "            w = w.unsqueeze(0).repeat(shape)\n",
    "            # w = torch.rand(*arg.shape, device=device)*weight_scale\n",
    "\n",
    "            w = w*arg\n",
    "\n",
    "\n",
    "            ws.append(w)\n",
    "\n",
    "\n",
    "            #-----------------------------------------------------------------------\n",
    "\n",
    "            g_decay = muster.clone()\n",
    "            g_decay.fill_(1)\n",
    "            g_decay = g_decay*arg\n",
    "            g_decays.append(g_decay)\n",
    "\n",
    "            g_rise = muster.clone()\n",
    "            g_rise.fill_(1)\n",
    "            g_rise = g_rise*arg\n",
    "            g_rises.append(g_rise)\n",
    "\n",
    "\n",
    "        # normalise ws\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return cells, states, mp, es, ws, g_decays, g_rises\n",
    "\n",
    "    def check_fire(mp):\n",
    "        activeness = (mp > threshold).float()\n",
    "        return activeness\n",
    "\n",
    "\n",
    "    def update_I_E(mp, gPs, states):\n",
    "\n",
    "        # generate currents based on gPs\n",
    "        cycle = len(gPs)\n",
    "        muster = torch.zeros_like(mp)\n",
    "        AMPA_currents = muster.clone()\n",
    "        NMDA_currents = muster.clone()\n",
    "        GABA_currents = muster.clone()\n",
    "        \n",
    "        for i in range(cycle):\n",
    "            temp_mp = broadcast_mp(mp, gPs[i])\n",
    "\n",
    "            AMPA_currents += (gMax_AMPA*gPs[i][0,...]*(temp_mp-rE_AMPA)).sum(dim=tuple(range(temp_mp.ndim - 2)))\n",
    "            NMDA_currents += (gMax_NMDA*gPs[i][1,...]*(1/(1+mg*torch.exp(-0.062*temp_mp)/3.57))*(temp_mp-rE_NMDA)).sum(dim=tuple(range(temp_mp.ndim - 2)))\n",
    "            GABA_currents += (gMax_GABA*gPs[i][2,...]*(temp_mp-rE_GABA)*(-1)).sum(dim=tuple(range(temp_mp.ndim - 2)))\n",
    "\n",
    "\n",
    "\n",
    "        Ireceptors = AMPA_currents + NMDA_currents + GABA_currents\n",
    "\n",
    "        # Ireceptors[Ireceptors >= 0] = 0.0\n",
    "\n",
    "\n",
    "        overflow_neurons = (Ireceptors <= current_threshold).float()\n",
    "\n",
    "        \n",
    "        sodium_currents = gMax_Na*torch.pow(states[0], 3) * states[2]*(mp-rE_Na)\n",
    "        potassium_currents = gMax_K*torch.pow(states[1], 4)*(mp-rE_K)\n",
    "        leaky_currents = gMax_leaky*(mp-rE_leaky)\n",
    "\n",
    "        total_I = - sodium_currents - potassium_currents - leaky_currents - Ireceptors\n",
    "\n",
    "\n",
    "        mp = mp + deltaTms*total_I/Cm\n",
    "        # mp = torch.clamp(mp, max=50.0)\n",
    "\n",
    "        return mp\n",
    "\n",
    "\n",
    "    # initialise everything\n",
    "\n",
    "    pixel_num = 10\n",
    "    feature_num = 8\n",
    "    E_num = 20\n",
    "    I_num = 4\n",
    "    Out_num = 5\n",
    "\n",
    "\n",
    "    #-----------connection matrices-------------\n",
    "    # ampa\n",
    "    In_con_E = torch.zeros(3, pixel_num, pixel_num, feature_num, E_num, E_num, device=device)\n",
    "    # all-to-all  connections\n",
    "    In_con_E[0].fill_(1.)\n",
    "\n",
    "    # the later two E_nums are the one sending out the connections/the center\n",
    "    # ampa and nmda\n",
    "    E_con_E = torch.zeros(E_num, E_num, E_num, E_num, device=device)\n",
    "    sigma_E_E = 2\n",
    "    max_E_E = 4.5\n",
    "    for i in range(E_num):\n",
    "        for j in range(E_num):\n",
    "            for k in range(E_num):\n",
    "                for l in range(E_num):\n",
    "                    project_center_x = k\n",
    "                    project_center_y = l\n",
    "\n",
    "                    # dx = min(abs(project_center_x - i), E_num-abs(project_center_x - i))\n",
    "                    # dy = min(abs(project_center_y - j), E_num-abs(project_center_y - j))\n",
    "                    \n",
    "                    dx = abs(project_center_x - i)\n",
    "                    dy = abs(project_center_y - j)\n",
    "\n",
    "                    euc_distance = math.sqrt(dx**2 + dy**2)\n",
    "                    \n",
    "\n",
    "                    # euc_distance = math.sqrt((project_center_x - i)**2 + (project_center_y - j)**2)\n",
    "                    E_con_E[i,j,k,l] = max_E_E*math.exp(-0.5*(euc_distance/sigma_E_E)**2)\n",
    "    E_con_E = E_con_E.permute(2, 3, 0, 1)\n",
    "    E_con_E = E_con_E.unsqueeze(0).repeat(3,1,1,1,1)\n",
    "    E_con_E[-1] = 0\n",
    "\n",
    "\n",
    "    # E to I connection matrix (p=0.1)\n",
    "    # ampa and nmda \n",
    "    E_con_I = torch.zeros(E_num, E_num, I_num, I_num, device=device)\n",
    "    num_elements = E_con_I.numel()\n",
    "    num_ones = max(1, int(num_elements * 0.1))  # Ensure at least 1 element\n",
    "    flat_indices = torch.randperm(num_elements)[:num_ones]\n",
    "    E_con_I.view(-1)[flat_indices] = 1\n",
    "    E_con_I = E_con_I.unsqueeze(0).repeat(3,1,1,1,1)\n",
    "    E_con_I[-1] = 0\n",
    "\n",
    "    # I to E connection matrix (p=0.024)\n",
    "    # gaba\n",
    "    I_con_E = torch.zeros(I_num, I_num, E_num, E_num, device=device)\n",
    "    num_elements = I_con_E.numel()\n",
    "    num_ones = max(1, int(num_elements * 0.024))  # Ensure at least 1 element\n",
    "    flat_indices = torch.randperm(num_elements)[:num_ones]\n",
    "    I_con_E.view(-1)[flat_indices] = 1\n",
    "    I_con_E = I_con_E.unsqueeze(0).repeat(3,1,1,1,1)\n",
    "    I_con_E[0] = 0\n",
    "    I_con_E[1] = 0\n",
    "\n",
    "    # I to I self connection (p=0.1)\n",
    "    # gaba\n",
    "    I_con_I = torch.zeros(I_num, I_num, I_num, I_num, device=device)\n",
    "    num_elements = I_con_I.numel()\n",
    "    num_ones = max(1, int(num_elements * 0.1))  # Ensure at least 1 element\n",
    "    flat_indices = torch.randperm(num_elements)[:num_ones]\n",
    "    I_con_I.view(-1)[flat_indices] = 1\n",
    "    I_con_I = I_con_I.unsqueeze(0).repeat(3,1,1,1,1)\n",
    "    I_con_I[0] = 0\n",
    "    I_con_I[1] = 0\n",
    "\n",
    "    # E to Out connection\n",
    "    # ampa\n",
    "    E_con_Out = torch.zeros(E_num, E_num, Out_num, Out_num, device=device)\n",
    "    sigma_E_Out = 2\n",
    "    max_E_Out = 1\n",
    "    # find the center point from Output to E\n",
    "    ratio = E_num/Out_num\n",
    "    for i in range(E_num):\n",
    "        for j in range(E_num):\n",
    "            for k in range(Out_num):\n",
    "                for l in range(Out_num):\n",
    "                    project_center_x = k*ratio\n",
    "                    project_center_y = l*ratio\n",
    "\n",
    "                    euc_distance = math.sqrt((project_center_x - i)**2 + (project_center_y - j)**2)\n",
    "                    E_con_Out[i,j,k,l] = max_E_Out*math.exp(-0.5*(euc_distance/sigma_E_Out)**2)\n",
    "    E_con_Out = E_con_Out.unsqueeze(0).repeat(3,1,1,1,1)\n",
    "    E_con_Out[1] = 0\n",
    "    E_con_Out[2] = 0\n",
    "\n",
    "\n",
    "    #----------E---------------------\n",
    "    E_cells, E_states, E_mp, E_es, E_ws, E_g_decays, E_g_rises = initialise(E_num, \n",
    "                                                                            [In_con_E, False, weight_scale], \n",
    "                                                                            [E_con_E, True, weight_scale], \n",
    "                                                                            [I_con_E, False, weight_scale*16])\n",
    "    # E_ws = normalise_weight(E_ws)\n",
    "    # this normalise step is not very necessary but meh \n",
    "    sums = E_ws[0][0].sum(dim=(0,1,2), keepdim=True)   # sum over presyn dims for each post neuron\n",
    "    E_ws[0][0] = E_ws[0][0]/sums*learning_rate*10\n",
    "\n",
    "\n",
    "    #----------I-----------------\n",
    "    I_cells, I_states, I_mp, I_es, I_ws, I_g_decays, I_g_rises = initialise(I_num, \n",
    "                                                                            [E_con_I, False, weight_scale], \n",
    "                                                                            [I_con_I, False, weight_scale])\n",
    "    # I_ws = normalise_weight(I_ws)\n",
    "\n",
    "\n",
    "    #-----------Output-------------\n",
    "    Out_cells, Out_states, Out_mp, Out_es, Out_ws, Out_g_decays, Out_g_rises = initialise(Out_num, \n",
    "                                                                                            [E_con_Out, True, weight_scale])\n",
    "    # Out_ws = normalise_weight(Out_ws)\n",
    "\n",
    "    # ------------------set to a good learning state-----------------------------------------\n",
    "    # if train:\n",
    "    #     with open(path + \"/Spiking_NN/datasets/SNN_states/pretty_good_states.pkl\", \"rb\") as f:\n",
    "    #         test_states = pickle.load(f)\n",
    "        \n",
    "    #     # I_ws = test_states[\"initial_I_ws\"]\n",
    "    #     E_ws = test_states[\"initial_E_ws\"]\n",
    "\n",
    "    #-------------------keep learning----------------------------------------------------------\n",
    "    if train:\n",
    "        with open(path + \"/Spiking_NN/datasets/SNN_states/train_zero.pkl\", \"rb\") as f:\n",
    "            last_states = pickle.load(f)\n",
    "        \n",
    "        # I_ws = test_states[\"initial_I_ws\"]\n",
    "        E_ws = last_states[\"E_ws\"]\n",
    "\n",
    "    if train:\n",
    "        states = {}\n",
    "        initial_E_ws = []\n",
    "        for i in E_ws:\n",
    "            initial_E_ws.append(i.detach().clone())\n",
    "        states[\"initial_E_ws\"] = initial_E_ws\n",
    "\n",
    "        initial_I_ws = []\n",
    "        for i in I_ws:\n",
    "            initial_I_ws.append(i.detach().clone())\n",
    "        states[\"initial_I_ws\"] = initial_I_ws\n",
    "\n",
    "        initial_Out_ws = []\n",
    "        for i in Out_ws:\n",
    "            initial_Out_ws.append(i.detach().clone())\n",
    "        states[\"initial_Out_ws\"] = initial_Out_ws\n",
    "    # -----------------------------------------run-------------------------------------------------\n",
    "\n",
    "\n",
    "    if not train:\n",
    "        # # use last weights\n",
    "        with open(path + \"/Spiking_NN/datasets/SNN_states/train_nine.pkl\", \"rb\") as f:\n",
    "        # with open(path + \"fire_data_gabor_binary.pkl\", \"rb\") as f:\n",
    "            states = pickle.load(f)\n",
    "        # E_ws[0][0] = states[\"E_ws\"][0][0]\n",
    "        E_ws = states[\"E_ws\"]\n",
    "        # I_ws = states[\"I_ws\"]\n",
    "        # Out_ws = states[\"Out_ws\"]\n",
    "\n",
    "\n",
    "\n",
    "    dims = list(range(one_pic.ndim))\n",
    "    new_order = [dims[-1]] + dims[:-1]\n",
    "    In_fires = one_pic.permute(new_order)\n",
    "    E_fires = torch.zeros((pointCount, E_num, E_num), device=device)\n",
    "    I_fires = torch.zeros((pointCount, I_num, I_num), device=device)\n",
    "    Out_fires = torch.zeros((pointCount, Out_num, Out_num), device=device)\n",
    "\n",
    "\n",
    "    for t in range(pointCount):\n",
    "        if t % 1000 == 0:  # every 50 steps\n",
    "            print(f\"Progress: {t}/{pointCount} ({100*t/pointCount:.1f}%)\")\n",
    "        # check mp and which fires then change connected layer activeness\n",
    "        # Input to E\n",
    "        In_fire = one_pic[:, :, :, t]\n",
    "\n",
    "        if E_mp.isnan().any():\n",
    "            print(\"oops\")\n",
    "            print(t)\n",
    "            data = {\n",
    "                # 'In_fires': In_fires*100,\n",
    "                'In_fires': In_fires,\n",
    "                'E_fires': E_fires,\n",
    "                'I_fires': I_fires,\n",
    "                'Out_fires': Out_fires\n",
    "            }\n",
    "\n",
    "            # with open(path + 'large_files/fires_new.pkl', 'wb') as f:\n",
    "            #     pickle.dump(data, f)\n",
    "            \n",
    "\n",
    "\n",
    "        # add spontaneous firing\n",
    "        # mask = torch.rand(E_mp.shape) < 0.001\n",
    "        # E_mp[mask] = spontaneous_mp\n",
    "        E_fire = check_fire(E_mp)\n",
    "        E_fire_lower = check_fire_lower(E_mp)\n",
    "        E_fires[t] = E_fire_lower\n",
    "        # E_fires[t] = E_fire\n",
    "        # E_fires[t] = E_mp\n",
    "\n",
    "\n",
    "        # mask = torch.rand(I_mp.shape) < 0.001\n",
    "        # I_mp[mask] = spontaneous_mp\n",
    "        I_fire = check_fire(I_mp)\n",
    "        I_fire_lower = check_fire_lower(I_mp)\n",
    "        I_fires[t] = I_fire_lower\n",
    "        # I_fires[t] = I_fire\n",
    "        # I_fires[t] = I_mp\n",
    "        \n",
    "        # mask = torch.rand(Out_mp.shape) < 0.001\n",
    "        # Out_mp[mask] = spontaneous_mp\n",
    "        Out_fire = check_fire(Out_mp)\n",
    "        Out_fire_lower = check_fire_lower(Out_mp)\n",
    "        Out_fires[t] = Out_fire_lower\n",
    "        # Out_fires[t] = Out_fire\n",
    "        # Out_fires[t] = Out_mp\n",
    "\n",
    "\n",
    "        # -----------------update gPs based on activeness--------------------------------\n",
    "        # update them by each layer connection, cannot do it at the same time because\n",
    "        # the shapes are different\n",
    "\n",
    "        E_states = update_states(E_mp, E_states) \n",
    "        E_es, E_g_decays, E_g_rises, E_gPs = update_gPs(E_es, E_ws, E_g_decays, E_g_rises, [In_fire, E_fire, I_fire], 1)\n",
    "\n",
    "\n",
    "        I_states = update_states(I_mp, I_states)\n",
    "        I_es, I_g_decays, I_g_rises, I_gPs = update_gPs(I_es, I_ws, I_g_decays, I_g_rises, [E_fire, I_fire], 0)\n",
    "\n",
    "\n",
    "        Out_states = update_states(Out_mp, Out_states)\n",
    "        Out_es, Out_g_decays, Out_g_rises, Out_gPs = update_gPs(Out_es, Out_ws, Out_g_decays, Out_g_rises, [E_fire], 0)\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------generate currents and voltages based on gPs-------------------------------\n",
    "\n",
    "        E_mp = update_I_E(E_mp, E_gPs, E_states)\n",
    "        # E_mp, E_ws = update_I_E(E_gPs, E_mp, E_states, E_ws)\n",
    "        \n",
    "\n",
    "        I_mp = update_I_E(I_mp, I_gPs, I_states)\n",
    "        # I_mp, I_ws = update_I_E(I_gPs, I_mp, I_states, I_ws)\n",
    "\n",
    "        Out_mp = update_I_E(Out_mp, Out_gPs, Out_states)\n",
    "        # Out_mp, Out_ws = update_I_E(Out_gPs, Out_mp, Out_states, Out_ws)\n",
    "\n",
    "        \n",
    "        # -------------------------update weights----------------------------------\n",
    "        # only In to E\n",
    "        # get the matrix of needed to change weight from the cons (Q: including the current time step?)\n",
    "        # take only the 400 time step before, equals to 20ms, which is the learning period in the paper\n",
    "        # for now update after 400 time steps \n",
    "        if train:\n",
    "            if t >= 400:\n",
    "                past_pre_fires = In_fires[t-399:t+1,:,:,:]\n",
    "                # using just multiplication\n",
    "                interactions = torch.einsum('tijk,ab->ijkabt', past_pre_fires, E_fire)\n",
    "                dw = (interactions*weight_values_matrix).sum(dim=-1)[0]\n",
    "                E_ws[0][0] += dw #*(1/(1+0.07*(t-400)))\n",
    "\n",
    "        # # only normalise the In to E connection's AMPA connection hence the [0][0]\n",
    "        # # E_ws[0][0] = E_ws[0][0]/E_ws[0][0].sum(dim=(0,1,2), keepdim=True)*weight_scale*5\n",
    "        sums = E_ws[0][0].sum(dim=(0,1,2), keepdim=True)   # sum over presyn dims for each post neuron\n",
    "        # # E_ws[0][0] = E_ws[0][0] / sums * (weight_scale * 5 / (E_ws[0][0].shape[2]*E_ws[0][0].shape[3])) #----this step looks weird\n",
    "        E_ws[0][0] = E_ws[0][0]/sums*learning_rate*10\n",
    "\n",
    "\n",
    "\n",
    "        # voltages.append(E_mp[10,10].cpu()-70)\n",
    "\n",
    "    data = {\n",
    "        # 'In_fires': In_fires*100,\n",
    "        'In_fires': In_fires,\n",
    "        'E_fires': E_fires,\n",
    "        'I_fires': I_fires,\n",
    "        'Out_fires': Out_fires\n",
    "    }\n",
    "\n",
    "    # skip showing the silence part between 600 - 1500\n",
    "    # data = {\n",
    "    #     'In_fires': torch.cat([In_fires[:600]*100,In_fires[1501:2500]*100, In_fires[3200:]], dim=0),\n",
    "    #     'E_fires': torch.cat([E_fires[:600], E_fires[1501:2500], E_fires[3200:]], dim=0),\n",
    "    #     'I_fires': torch.cat([I_fires[:600], I_fires[1501:2500], I_fires[3200:]], dim=0),\n",
    "    #     'Out_fires': torch.cat([Out_fires[:600], Out_fires[1501:2500], Out_fires[3200:]], dim=0)\n",
    "    # }\n",
    "\n",
    "    # data = {\n",
    "    #     'In_fires': In_fires[1600:]*100,\n",
    "    #     # 'In_fires': In_fires,\n",
    "    #     'E_fires': E_fires[1600:],\n",
    "    #     'I_fires': I_fires[1600:],\n",
    "    #     'Out_fires': Out_fires[1600:]\n",
    "    # }\n",
    "\n",
    "    if train:\n",
    "        after_E_ws = []\n",
    "        for i in E_ws:\n",
    "            after_E_ws.append(i.detach().clone())\n",
    "        states[\"E_ws\"] = after_E_ws\n",
    "        # states[\"E_ws\"] = E_ws[0][0].detach().clone()\n",
    "        \n",
    "        # states = {\n",
    "        #     \"E_ws\": E_ws\n",
    "        #     # \"I_ws\": I_ws,\n",
    "        #     # \"Out_ws\": Out_ws\n",
    "        # }\n",
    "\n",
    "\n",
    "        with open(path + 'Spiking_NN/datasets/SNN_states/train_nine.pkl', 'wb') as f:\n",
    "            pickle.dump(states, f)\n",
    "    print(pic_index)\n",
    "    sum = E_fires[500:1000].sum(dim=(1,2)) \n",
    "    if torch.max(sum) > 12:\n",
    "        print(\"same\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
